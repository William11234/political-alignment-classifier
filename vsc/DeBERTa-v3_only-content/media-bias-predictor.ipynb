{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Media Bias Classifier\n",
    "\n",
    "This project proposes a machine learning-based News Bias Detection System that analyses news articles to identify potential biases in reporting. By leveraging natural language processing (NLP) and explainable AI techniques, the system will assess textual content and detect linguistic patterns that indicate bias.\n",
    "\n",
    "Bias in news media can shape public opinion and influence decision-making, making it essential to recognize and mitigate biased reporting. Traditional methods of bias detection rely on human judgment, which is subjective, time-consuming, and inconsistent. This project aims to build an automated and transparent system for detecting bias, promoting more critical and informed media consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\wtert\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import Trainer, TrainingArguments, BertForSequenceClassification, BertTokenizer, TrainerCallback\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Preprocessing Functions\n",
    "\n",
    "These functions clean and prepare the input for **DeBERTa**. It ensures the model focusses on meaningful, consistent, and token-friendly content.\n",
    "\n",
    "- **üß± Boilerplate Removal:** Removes generic news agency references (like \"According to CNN\" or \"As reported by Reuters\") to reduce noise in the input text.\n",
    "- - ‚úÖ *Why it matters:* These phrases don‚Äôt help the model learn bias‚Äîthey're common across sources and can act as noise.\n",
    "\n",
    "- **üî§ Accent Removal:** Strips accents from letters (e.g., ‚Äú√©‚Äù becomes ‚Äúe‚Äù), improving consistency across languages. \n",
    "- - ‚úÖ *Why it matters:* Helps reduce unnecessary vocabulary complexity for the tokenizer.\n",
    "\n",
    "- **üßº Preprocess_for_bert:** Applies all the text cleaning: removes boilerplate, strips accents, removes non-ASCII chars, and lowercases it.\n",
    "- - ‚úÖ *Why it matters:* Makes the text clean and simple for the tokenizer. This should be consistent throughout every text to avoid noise and bias.\n",
    "\n",
    "- **üßº Preprocess_for_bert_title:** Same as the function above, but without lowercasing.\n",
    "- - ‚úÖ *Why without lowercasing?* The title is shorter and often includes certain context through capitalization. For example: \n",
    "\n",
    "*May to lead Brexit talks*\n",
    "\n",
    "**Original:**\n",
    "Refers to Theresa May, the former UK prime minister.\n",
    "\n",
    "**Lowercased:**\n",
    "*may to lead brexit talks*\n",
    "Now it could look like it's using the month of May or the modal verb ‚Äúmay‚Äù ‚Äî completely changes meaning or adds ambiguity.\n",
    "\n",
    "It might not look like a big deal to the human brain, but we have to be specific when training such a model.\n",
    "\n",
    "- **‚úÇÔ∏è truncate_for_model:** Fits both title and content into a maximum token limit, prioritizing the title. The line *remaining = max_total_tokens - len(title_tokens) - 3* accounts for 1 [CLS] token (added automatically by tokenizer) 2 [SEP] tokens (between and after title/content). Then *content_tokens = content_tokens[:max(0, remaining)]* truncates the content if it doesn't fit.\n",
    "- - ‚úÖ *Why it matters:* Transformers have a max token limit. This is making sure it never goes over that, but still prioritizes the title.\n",
    "\n",
    "- **üéØ difficulty_score:** Simple scoring function based on total word count of title and content combined.\n",
    "- - ‚úÖ *Why it matters:* Used for curriculum sampling (easy ‚Üí hard progression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_boilerplate(text):\n",
    "    boilerplate_patterns = [\n",
    "        r\"(?:According to|As reported by|As per)?\\s?(CNN|Fox News|Reuters|BBC|The New York Times|AP|Washington Post)[,:\\s]*(reports|says|states)?\",\n",
    "        r\"(?:Reported by|From the article in)?\\s?(CNN|Fox News|Reuters|BBC|The New York Times|AP|Washington Post)\"\n",
    "    ]\n",
    "    for pattern in boilerplate_patterns:\n",
    "        text = re.sub(pattern, \"\", text, flags=re.IGNORECASE)\n",
    "    return text.strip()\n",
    "\n",
    "def remove_accents(text):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', text)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def preprocess_for_bert(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = remove_boilerplate(text)\n",
    "    text = remove_accents(text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    return text.lower().strip()\n",
    "    \n",
    "def truncate_for_model(content, max_total_tokens=384):\n",
    "    content_tokens = tokenizer.tokenize(content)\n",
    "    \n",
    "    content_tokens = content_tokens[:max(0, max_total_tokens)]\n",
    "    \n",
    "    return tokenizer.convert_tokens_to_string(content_tokens)\n",
    "\n",
    "def difficulty_score(title, content):\n",
    "    return len(f\"{title} {content}\".split())\n",
    "\n",
    "def compute_tfidf_scores(texts):\n",
    "    \"\"\"\n",
    "    Returns average TF-IDF score for each text.\n",
    "    Lower score = more ambiguous, so harder to classify.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(max_features=10000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    mean_scores = tfidf_matrix.mean(axis=1)\n",
    "    return np.array(mean_scores).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeBERTa-v3\n",
    "\n",
    "**DeBERTa-v3 (Decoding-enhanced BERT with disentangled attention)** is an advanced NLP model developed by Microsoft. It improves upon the original BERT by incorporating two key innovations: disentangled attention and enhanced decoding. Disentangled attention allows the model to better capture the relationship between words and their positions, while enhanced decoding improves the model's understanding of context. These advancements enable DeBERTa-v3 to outperform BERT and other models in many NLP tasks, providing more accurate results for complex language understanding.\n",
    "\n",
    "### üß† 1. Disentangled Attention: Better Word + Position Understanding\n",
    "In BERT, word content and position are combined into a single embedding before being passed to the self-attention layers. This means the model might not always clearly separate what a word means from where it appears in the sentence.\n",
    "\n",
    "DeBERTa splits the meaning of words from their positions, allowing it to analyze how word placement affects meaning more precisely.\n",
    "\n",
    "Example:\n",
    "\n",
    "\"Only Alice punched Bob.\"\n",
    "\n",
    "\"Bob punched only Alice.\"\n",
    "\n",
    "These sentences use the same words, but mean very different things.\n",
    "DeBERTa's disentangled attention understands the difference better than BERT, which mixes meaning and position too early.\n",
    "\n",
    "üß© This helps the model recognize who did what, and how words like \"only\" change that meaning depending on position.\n",
    "\n",
    "### üîÅ 2. Enhanced Mask Decoder: Sharper Context Grasp\n",
    "In BERT, the model predicts masked tokens (like [MASK]) using a simple linear layer on top of the encoder output. A simple linear layer just takes the number-y output for a word from BERT and runs it through a math formula (matrix multiplication + bias) to guess what the masked word should be. It‚Äôs like plugging the word's info into a calculator that spits out a score for every word in the dictionary, then picking the one with the highest score.\n",
    "\n",
    "DeBERTa's decoder uses more contextual information than BERT to fill in missing or masked words during training.\n",
    "\n",
    "Example:\n",
    "\n",
    "\"The cat sat on the [MASK].\"\n",
    "\n",
    "üîç DeBERTa looks deeper into:\n",
    "\n",
    "- Grammatical structure\n",
    "- Likely surfaces a cat sits on\n",
    "- Sentence semantics\n",
    "\n",
    "It might confidently predict \"mat\", while BERT might guess less precisely (e.g., ‚Äúsofa‚Äù, ‚Äúfloor‚Äù).\n",
    "\n",
    "üìö This makes DeBERTa more accurate for tasks that rely on subtle language cues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîé Analytic Approach\n",
    "\n",
    "Detecting bias in articles might be an unclear objective, due to its abstraction. The first question to give attention to could be how exactly we detect bias, but there might be a better way to approach this. Instead, asking what bias is and how we should define it could provide more clarity.\n",
    "\n",
    "**Multi-Class Classification** is presumably the better option. It eliminates the need for something to be classified as unbiased, as the left, center, and right all contain some form of bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_folder = r\"C:\\Fontys\\Semester4\\MediaBias_Predictor\\Article-Bias-Prediction-main\\data\\jsons\"\n",
    "\n",
    "# data = []\n",
    "\n",
    "# # Loop through JSON files\n",
    "# for filename in os.listdir(json_folder):\n",
    "#     if filename.endswith(\".json\"):\n",
    "#         file_path = os.path.join(json_folder, filename)\n",
    "#         with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             article = json.load(f)\n",
    "            \n",
    "#             # Extract only the fields present in the JSON\n",
    "#             data.append({\n",
    "#                 \"ID\": article.get(\"ID\", \"\"),  \n",
    "#                 \"topic\": article.get(\"topic\", \"\"),  \n",
    "#                 \"source\": article.get(\"source\", \"\"),  \n",
    "#                 \"title\": article.get(\"title\", \"\"),  \n",
    "#                 \"date\": article.get(\"date\", \"\"),  \n",
    "#                 \"authors\": article.get(\"authors\", \"\"),  \n",
    "#                 \"content\": article.get(\"content\", \"\"),  \n",
    "#                 \"bias_text\": article.get(\"bias_text\", \"\"),  # Bias category (e.g., left, center, right)\n",
    "#                 \"url\": article.get(\"url\", \"\"),  \n",
    "#                 \"source_url\": article.get(\"source_url\", \"\")  \n",
    "#             })\n",
    "\n",
    "df = pd.read_csv('../news_bias_data.csv')\n",
    "\n",
    "\n",
    "# df.to_csv(\"news_bias_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>topic</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>authors</th>\n",
       "      <th>content</th>\n",
       "      <th>bias_text</th>\n",
       "      <th>url</th>\n",
       "      <th>source_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004Gt3gcsotuiYmz</td>\n",
       "      <td>terrorism</td>\n",
       "      <td>New York Times - News</td>\n",
       "      <td>Bomb Suspect Changed After Trip Abroad, Friend...</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>N. R. Kleinfield</td>\n",
       "      <td>Besides his most recent trip to Quetta , Mr. R...</td>\n",
       "      <td>left</td>\n",
       "      <td>http://www.nytimes.com/2016/09/20/nyregion/ahm...</td>\n",
       "      <td>www.nytimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00eP4XD3VdMmHITE</td>\n",
       "      <td>supreme_court</td>\n",
       "      <td>Vox</td>\n",
       "      <td>Why Susan Collins claims she‚Äôs being bribed ov...</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>Emily Stewart, Terry Nguyen, Rebecca Jennings,...</td>\n",
       "      <td>Is Maine Republican Sen. Susan Collins being b...</td>\n",
       "      <td>left</td>\n",
       "      <td>https://www.vox.com/policy-and-politics/2018/9...</td>\n",
       "      <td>www.vox.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00FTGIZEd6B8zQ4U</td>\n",
       "      <td>education</td>\n",
       "      <td>Ezra Klein</td>\n",
       "      <td>Poll: Prestigious Colleges Won't Make You Happ...</td>\n",
       "      <td>2014-05-06</td>\n",
       "      <td>Anya Kamenetz</td>\n",
       "      <td>Poll : Prestigious Colleges Wo n't Make You Ha...</td>\n",
       "      <td>left</td>\n",
       "      <td>http://www.npr.org/blogs/thetwo-way/2014/05/06...</td>\n",
       "      <td>www.npr.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00HGGqBRf1kzPRlg</td>\n",
       "      <td>us_house</td>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>Paul Ryan Reportedly Says No Chance for Border...</td>\n",
       "      <td>2017-09-12</td>\n",
       "      <td>Ian Mason</td>\n",
       "      <td>House Speaker Paul Ryan , at a private dinner ...</td>\n",
       "      <td>right</td>\n",
       "      <td>http://www.breitbart.com/big-government/2017/0...</td>\n",
       "      <td>www.breitbart.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00IzI5ynahBVtC9l</td>\n",
       "      <td>white_house</td>\n",
       "      <td>Guest Writer - Left</td>\n",
       "      <td>OPINION: Trump seeking change of legal fortune...</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>Analysis Stephen Collinson</td>\n",
       "      <td>( CNN ) President Donald Trump has reason to h...</td>\n",
       "      <td>left</td>\n",
       "      <td>https://www.cnn.com/2019/07/11/politics/donald...</td>\n",
       "      <td>www.cnn.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID          topic                 source  \\\n",
       "0  004Gt3gcsotuiYmz      terrorism  New York Times - News   \n",
       "1  00eP4XD3VdMmHITE  supreme_court                    Vox   \n",
       "2  00FTGIZEd6B8zQ4U      education             Ezra Klein   \n",
       "3  00HGGqBRf1kzPRlg       us_house         Breitbart News   \n",
       "4  00IzI5ynahBVtC9l    white_house    Guest Writer - Left   \n",
       "\n",
       "                                               title        date  \\\n",
       "0  Bomb Suspect Changed After Trip Abroad, Friend...  2016-09-20   \n",
       "1  Why Susan Collins claims she‚Äôs being bribed ov...  2018-09-12   \n",
       "2  Poll: Prestigious Colleges Won't Make You Happ...  2014-05-06   \n",
       "3  Paul Ryan Reportedly Says No Chance for Border...  2017-09-12   \n",
       "4  OPINION: Trump seeking change of legal fortune...  2019-07-11   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                   N. R. Kleinfield   \n",
       "1  Emily Stewart, Terry Nguyen, Rebecca Jennings,...   \n",
       "2                                      Anya Kamenetz   \n",
       "3                                          Ian Mason   \n",
       "4                         Analysis Stephen Collinson   \n",
       "\n",
       "                                             content bias_text  \\\n",
       "0  Besides his most recent trip to Quetta , Mr. R...      left   \n",
       "1  Is Maine Republican Sen. Susan Collins being b...      left   \n",
       "2  Poll : Prestigious Colleges Wo n't Make You Ha...      left   \n",
       "3  House Speaker Paul Ryan , at a private dinner ...     right   \n",
       "4  ( CNN ) President Donald Trump has reason to h...      left   \n",
       "\n",
       "                                                 url         source_url  \n",
       "0  http://www.nytimes.com/2016/09/20/nyregion/ahm...    www.nytimes.com  \n",
       "1  https://www.vox.com/policy-and-politics/2018/9...        www.vox.com  \n",
       "2  http://www.npr.org/blogs/thetwo-way/2014/05/06...        www.npr.org  \n",
       "3  http://www.breitbart.com/big-government/2017/0...  www.breitbart.com  \n",
       "4  https://www.cnn.com/2019/07/11/politics/donald...        www.cnn.com  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleaning contents and titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Besides his most recent trip to Quetta , Mr. R...</td>\n",
       "      <td>besides his most recent trip to quetta , mr. r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Maine Republican Sen. Susan Collins being b...</td>\n",
       "      <td>is maine republican sen. susan collins being b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poll : Prestigious Colleges Wo n't Make You Ha...</td>\n",
       "      <td>poll : prestigious colleges wo n't make you hp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>House Speaker Paul Ryan , at a private dinner ...</td>\n",
       "      <td>house speaker paul ryan , at a private dinner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>( CNN ) President Donald Trump has reason to h...</td>\n",
       "      <td>() president donald trump has reason to hope h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Besides his most recent trip to Quetta , Mr. R...   \n",
       "1  Is Maine Republican Sen. Susan Collins being b...   \n",
       "2  Poll : Prestigious Colleges Wo n't Make You Ha...   \n",
       "3  House Speaker Paul Ryan , at a private dinner ...   \n",
       "4  ( CNN ) President Donald Trump has reason to h...   \n",
       "\n",
       "                                     cleaned_content  \n",
       "0  besides his most recent trip to quetta , mr. r...  \n",
       "1  is maine republican sen. susan collins being b...  \n",
       "2  poll : prestigious colleges wo n't make you hp...  \n",
       "3  house speaker paul ryan , at a private dinner ...  \n",
       "4  () president donald trump has reason to hope h...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cleaned_content\"] = df[\"content\"].apply(preprocess_for_bert)\n",
    "\n",
    "df[[\"content\", \"cleaned_content\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ÑπÔ∏è Splitting the data\n",
    "\n",
    "This cell below handles the data splitting to evenly distribute the left, center, and right-winged data. This is used if the model needs to be trained on less data, so that even if you take a portion of the dataset, it is still evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37554, 11)\n"
     ]
    }
   ],
   "source": [
    "features = [\"content\", \"bias_text\"]\n",
    "\n",
    "\"\"\"left_df = df[df[\"bias_text\"] == \"left\"]\n",
    "center_df = df[df[\"bias_text\"] == \"center\"]\n",
    "right_df = df[df[\"bias_text\"] == \"right\"]\n",
    "\n",
    "total_samples = 10000\n",
    "\n",
    "# Randomly sample from each class\n",
    "left_sampled = left_df.sample(n=total_samples, random_state=42)\n",
    "center_sampled = center_df.sample(n=total_samples, random_state=42)\n",
    "right_sampled = right_df.sample(n=total_samples, random_state=42)\n",
    "\n",
    "df = pd.concat([left_sampled, center_sampled, right_sampled])\n",
    "\n",
    "# Shuffle the final dataset\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\"\"\"\n",
    "\n",
    "df[features].head()\n",
    "# print(left_df.shape, center_df.shape, right_df.shape)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **df.sample(frac=1, random_state=42)** means:\n",
    "\n",
    "- - **frac=1** ‚Üí take 100% of the DataFrame, but in random order.\n",
    "\n",
    "- - **random_state=42** ‚Üí makes the randomness repeatable, so every time you run it, it shuffles in the same way (helpful for debugging or reproducibility).\n",
    "\n",
    "- **.reset_index(drop=True)**:\n",
    "\n",
    "- - After shuffling, the original row indices are scrambled too.\n",
    "\n",
    "- - **reset_index(drop=True)** gives the DataFrame new clean row numbers (0, 1, 2, ...) and drops the old indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                    0\n",
      "topic                 0\n",
      "source                0\n",
      "title                 0\n",
      "date               4407\n",
      "authors            9668\n",
      "content               0\n",
      "bias_text             0\n",
      "url                   0\n",
      "source_url            0\n",
      "cleaned_content       0\n",
      "dtype: int64\n",
      "bias_text\n",
      "right     13734\n",
      "left      13005\n",
      "center    10815\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataset after removing missing values:\n",
      "(37554, 11)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check the distribution of bias_text labels\n",
    "print(df['bias_text'].value_counts())\n",
    "\n",
    "print(\"\\nDataset after removing missing values:\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **BERT** model requires much less data preprocessing, since it is pre-trained on **raw text**. It is in fact helpful to include the things that we otherwise exclude from other models, because it provides a certain context that BERT recognizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias_text</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bias_text  label_id\n",
       "0      left         1\n",
       "1      left         1\n",
       "2      left         1\n",
       "3     right         2\n",
       "4      left         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"label_id\"] = label_encoder.fit_transform(df[\"bias_text\"]) # Representing left, center, right as 0, 1, 2\n",
    "\n",
    "df[[\"bias_text\", \"label_id\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ÜóÔ∏è Tokenization\n",
    "\n",
    "Before text can go into DeBERTa, it has to be converted into numbers (tokens).\n",
    "\n",
    "- It Splits text into subwords (e.g., \"unbelievable\" ‚Üí \"un\", \"##believable\").\n",
    "\n",
    "- Maps words/subwords to token IDs that DeBERTa understands.\n",
    "\n",
    "- Pads or truncates text to a fixed length (so batches are consistent).\n",
    "\n",
    "- Returns attention masks (to tell the model which tokens are real vs. padding).\n",
    "\n",
    "Two example sentences:\n",
    "\n",
    "- *L, did you know* (5 tokens)\n",
    "- *Gods of death love apples!* (6 tokens)\n",
    "\n",
    "If we set the max_length to be 8, it will allow a maximum of 8 tokens. If a piece of text has more than that, it truncates it down to 8, and if it has less, it adds padding to get it to 8. In the example sentences, it would be represented as follows:\n",
    "\n",
    "- *L, did you know [PAD] [PAD] [PAD]* (8 tokens)\n",
    "- *Gods of death love apples! [PAD] [PAD]* (8 tokens)\n",
    "\n",
    "The **attention mask** is like a signal for the model to know which tokens are real words and which ones are padding (which should be ignored). Padding is displayed as 0 and real words as 1.\n",
    "\n",
    "The attention mask for *L, did you know [PAD] [PAD] [PAD]* would look like *[1, 1, 1, 1, 1, 0, 0, 0]*.\n",
    "\n",
    "#### Why is this important?\n",
    "Deep learning models like DeBERTa process data in batches. Having all sentences the same length allows the model to process them simultaneously. If sentences have different lengths, the model would need to deal with each sentence one by one. Computers use matrices to process data efficiently. If sentences have different lengths, you can't create a matrix because the rows (sentences) won't have the same number of columns (tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Training Pipeline\n",
    "\n",
    "### üìä NewsDataset class:\n",
    "\n",
    "- __init__: Stores the tokenized input (encodings) and the labels.\n",
    "\n",
    "- __len__: Returns the total number of samples in the dataset. Required so the model knows how many items to expect.\n",
    "\n",
    "- __getitem__: When the model asks for a specific item (e.g., the 5th article), this method: Converts the data into PyTorch tensors and returns a dictionary with the correct format: input_ids, attention_mask, and labels\n",
    "\n",
    "`item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}`\n",
    "This line is creating a new dictionary called item. It goes through each key-value pair in self.encodings, which is a dictionary containing the tokenized input data.\n",
    "`clone().detach()` is used to create a new tensor that's independent of the original one. It is like a copy to not mess with the original one.\n",
    "\n",
    "#### Tensors\n",
    "\n",
    "Tensors can be seen as multi-dimensional arrays:\n",
    "\n",
    "- Scalar (0D) -> 3,14 -> torch.tensor(3.14)\n",
    "- Vector (1D) -> [1, 2, 3] -> torch.tensor([1, 2, 3])\n",
    "- Matrix (2D) -> [[1, 2], [3, 4]] -> torch.tensor([[1, 2], [3, 4]])\n",
    "- Tensor (3D+) -> [[[...], [...]], [[...], [...]]] -> Used in images, NLP, etc.\n",
    "\n",
    "In NLP with BERT:\n",
    "\n",
    "A sentence becomes a 1D tensor (list of token IDs)\n",
    "\n",
    "A batch of sentences becomes a 2D tensor (each row is a sentence)\n",
    "\n",
    "### üìã CurriculumTrainer class\n",
    "\n",
    "- **get_train_dataloader**: This method is responsible for returning the dataloader used during training. Normally, the dataloader would shuffle training data, but here we turn that off to preserve the \"easy-to-hard\" order required for curriculum learning.\n",
    "\n",
    "- **collate_fn**: The collate_fn is a function used to combine or ‚Äúbatch‚Äù data into a single batch. It is needed when you have different types of data, or the data isn't structured in a way that can be directly fed into the model. It makes sure that each input in the batch is the same size. The tokenizer does this too by adding padding to the text. The collate_fn function does the same, but provides more control.\n",
    "\n",
    "- **drop_last=False**: When dividing data into batches, sometimes you end up with a smaller batch at the end because the total data isn't a perfect multiple of the batch size. This setting says makes sure to keep that batch. Even though it's smaller, it still gets fed into the model.\n",
    "\n",
    "### ü§î StratifiedKFold\n",
    "**K-Fold Cross-Validation** is a technique used in machine learning to evaluate the performance of a model. The dataset is divided into **k** equal-sized subsets or \"folds\". The model is trained on **k-1** folds and tested on the remaining fold. This is repeated **k** times, with each fold used exactly once for testing and the remaining ones for training. **Stratified K-Fold** ensures each fold has a similar distribution of the target labels, making it more reliable for evaluating models on imbalanced datasets. The dataset used already has evenly distributed labels, but it can still act as a safety net.\n",
    "\n",
    "### üë®‚Äçüéì Curriculum Learning\n",
    "\n",
    "Instead of feeding the model data randomly, curriculum learning starts with easier examples first, and moves on to harder ones later, because the model starts off being \"stupid\".\n",
    "\n",
    "##### üîé Line by line breakdown\n",
    "\n",
    "`train_data = [(titles[i], df[\"content\"].iloc[i], labels[i]) for i in train_index]` takes the training indices from the split. For each index it grabs the:\n",
    "- title\n",
    "- content\n",
    "- label\n",
    "\n",
    "It creates a list of tuples like:\n",
    "`[(\"Why something is great\", \"Something is amazing, because...\", 0), (...), ...]`\n",
    "\n",
    "`train_titles, train_contents, train_labels = zip(*train_data)` creates separate lists for all the titles, contents, and labels.\n",
    "\n",
    "`train_texts_full = [f\"{title} {content}\" for title, content in zip(train_titles, train_contents)]` combines the title and content into one text.\n",
    "\n",
    "`tfidf_scores = compute_tfidf_scores(train_texts_full)` High TF-IDF score ‚Üí article is unique, has rare words. Low score ‚Üí article is generic, uses common words.\n",
    "\n",
    "`train_data_with_scores = list(zip(train_titles, train_contents, train_labels, tfidf_scores))` now each sample has a score.\n",
    "\n",
    "`train_data_with_scores.sort(key=lambda x: x[3], reverse=True)` sorts the data using the fourth element of the tuple, which is the **tfidf_score**. `reverse=True` determines that the order should be descending.\n",
    "\n",
    "`train_titles, train_contents, train_labels, _ = zip(*train_data_with_scores)` now the data is sorted using the tfidf scores, so they can be ignored and the data can now be used for curriculum learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wtert\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "Training label distribution: Counter({2: 9156, 1: 8670, 0: 7210})\n",
      "Validation label distribution: Counter({2: 4578, 1: 4335, 0: 3605})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9390' max='9390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9390/9390 2:12:15, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.521346</td>\n",
       "      <td>0.791820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.661159</td>\n",
       "      <td>0.778719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.654579</td>\n",
       "      <td>0.811392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.748139</td>\n",
       "      <td>0.820578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.770841</td>\n",
       "      <td>0.841109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.784108</td>\n",
       "      <td>0.841109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.8411\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      3605\n",
      "           1       0.84      0.86      0.85      4335\n",
      "           2       0.86      0.84      0.85      4578\n",
      "\n",
      "    accuracy                           0.84     12518\n",
      "   macro avg       0.84      0.84      0.84     12518\n",
      "weighted avg       0.84      0.84      0.84     12518\n",
      "\n",
      "\n",
      "===== Fold 2 =====\n",
      "Training label distribution: Counter({2: 9156, 1: 8670, 0: 7210})\n",
      "Validation label distribution: Counter({2: 4578, 1: 4335, 0: 3605})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9390' max='9390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9390/9390 1:51:19, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244839</td>\n",
       "      <td>0.908771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242425</td>\n",
       "      <td>0.919636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272056</td>\n",
       "      <td>0.930420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.350709</td>\n",
       "      <td>0.924589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301155</td>\n",
       "      <td>0.941125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263759</td>\n",
       "      <td>0.945838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Accuracy: 0.9458\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      3605\n",
      "           1       0.94      0.96      0.95      4335\n",
      "           2       0.96      0.95      0.96      4578\n",
      "\n",
      "    accuracy                           0.95     12518\n",
      "   macro avg       0.94      0.94      0.94     12518\n",
      "weighted avg       0.95      0.95      0.95     12518\n",
      "\n",
      "\n",
      "===== Fold 3 =====\n",
      "Training label distribution: Counter({2: 9156, 1: 8670, 0: 7210})\n",
      "Validation label distribution: Counter({2: 4578, 1: 4335, 0: 3605})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9390' max='9390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9390/9390 4:01:28, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.093836</td>\n",
       "      <td>0.968046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.146159</td>\n",
       "      <td>0.957741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140817</td>\n",
       "      <td>0.969564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.081093</td>\n",
       "      <td>0.983783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.064833</td>\n",
       "      <td>0.987458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.059774</td>\n",
       "      <td>0.988736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Accuracy: 0.9887\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3605\n",
      "           1       0.99      0.99      0.99      4335\n",
      "           2       0.99      0.99      0.99      4578\n",
      "\n",
      "    accuracy                           0.99     12518\n",
      "   macro avg       0.99      0.99      0.99     12518\n",
      "weighted avg       0.99      0.99      0.99     12518\n",
      "\n",
      "\n",
      "===== Cross-Validation Complete =====\n",
      "Mean Accuracy: 0.9252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, DebertaV2ForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "from collections import Counter\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=3)\n",
    "\n",
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "class CurriculumTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        # Disable shuffling for curriculum learning\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.args.train_batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=self.data_collator,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "contents = df[\"cleaned_content\"].tolist()\n",
    "labels = df[\"label_id\"].tolist()\n",
    "accuracies = []  # Initialize accuracies list for storing fold results\n",
    "\n",
    "stratified_kfold = skf(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=3)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(stratified_kfold.split(contents, labels)):\n",
    "    print(f\"\\n===== Fold {fold + 1} =====\")\n",
    "\n",
    "    # STEP 1: Grab training data using the indices from StratifiedKFold\n",
    "    train_data = [\n",
    "        (df[\"cleaned_content\"].iloc[i], labels[i]) for i in train_index\n",
    "    ]\n",
    "\n",
    "    # STEP 2: Unpack (unzip) train_data into individual lists\n",
    "    train_contents, train_labels = zip(*train_data)\n",
    "\n",
    "    # STEP 3: Compute TF-IDF scores for all the combined texts\n",
    "    tfidf_scores = compute_tfidf_scores(train_contents)\n",
    "\n",
    "    # STEP 4: Attach the scores to the data for sorting\n",
    "    train_data_with_scores = list(zip(train_contents, train_labels, tfidf_scores))\n",
    "\n",
    "    # STEP 5: Sort the data ‚Äî lowest TF-IDF (most ambiguous) comes last in curriculum\n",
    "    train_data_with_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # STEP 6: Unpack the sorted data (ignore the scores now)\n",
    "    train_contents, train_labels, _ = zip(*train_data_with_scores)\n",
    "\n",
    "    val_contents = [df[\"cleaned_content\"].iloc[i] for i in val_index]\n",
    "    val_labels = [labels[i] for i in val_index]\n",
    "\n",
    "    print(f\"Training label distribution: {Counter(train_labels)}\")\n",
    "    print(f\"Validation label distribution: {Counter(val_labels)}\")\n",
    "\n",
    "    train_texts = [truncate_for_model(c) for c in train_contents]\n",
    "    val_texts = [truncate_for_model(c) for c in val_contents]\n",
    "\n",
    "    train_encodings = tokenizer(train_texts, max_length=384, truncation=True, padding=True, return_tensors='pt')\n",
    "    val_encodings = tokenizer(val_texts, max_length=384, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "    train_dataset = NewsDataset(train_encodings, train_labels)\n",
    "    val_dataset = NewsDataset(val_encodings, val_labels)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_fold_{fold}\",\n",
    "        num_train_epochs=6,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=None,\n",
    "        logging_steps=999999,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_accuracy\",\n",
    "        save_total_limit=1,\n",
    "        report_to=\"none\",\n",
    "        learning_rate=3e-5,\n",
    "        fp16=True,\n",
    "        lr_scheduler_type='cosine',\n",
    "        gradient_accumulation_steps=2,\n",
    "    )\n",
    "\n",
    "    def compute_accuracy(pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = np.argmax(pred.predictions, axis=1)\n",
    "        accuracy = (preds == labels).mean()\n",
    "        return {\"accuracy\": accuracy}\n",
    "\n",
    "    trainer = CurriculumTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_accuracy\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_result = trainer.evaluate()\n",
    "    trainer.save_model(f\"saved_models/fold_{fold}\")\n",
    "    tokenizer.save_pretrained(f\"saved_models/fold_{fold}\")\n",
    "    print(f\"Fold {fold + 1} Accuracy: {eval_result['eval_accuracy']:.4f}\")\n",
    "    accuracies.append(eval_result['eval_accuracy'])\n",
    "\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(val_labels, pred_labels))\n",
    "\n",
    "print(\"\\n===== Cross-Validation Complete =====\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîé Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Generate the confusion matrix\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43mval_labels\u001b[49m, pred_labels)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Normalize the confusion matrix to show percentages\u001b[39;00m\n\u001b[0;32m      7\u001b[0m cm_percentage \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m cm\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(val_labels, pred_labels)\n",
    "\n",
    "# Normalize the confusion matrix to show percentages\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Display the confusion matrix with percentages\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Percentages)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
